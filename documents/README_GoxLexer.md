# Gox Lexer - Influencias, Decisiones y Pruebas

Este proyecto toma inspiraci√≥n directa del cap√≠tulo **"Scanning"** del libro *Crafting Interpreters*. A continuaci√≥n explico c√≥mo fue el proceso de interpretaci√≥n, adaptaci√≥n y desarrollo del lexer de Gox.

---

## Influencia del Libro

El cap√≠tulo del libro est√° escrito en Java, lo que represent√≥ un reto inicial. Sin embargo, logr√© reinterpretar y traducir su enfoque a Python, respetando la l√≥gica y estructura general del esc√°ner.

---

## Estructura y L√≥gica del Lexer

### TokenType.py

Inspirado en el uso de `enum class` del libro, utilic√© un enfoque similar en Python para organizar los tipos de tokens. Sin embargo, para lograr un mapeo m√°s preciso y eficiente, incorpor√© diccionarios. Aqu√≠ est√°n los tres diccionarios clave:

- **`SINGLE_CHAR_TOKENS`**:  
  Define tokens individuales, es decir, aquellos formados por un solo car√°cter.

- **`TOKEN_LITERALS`**:  
  Incluye literales e identificadores utilizados durante el escaneo.

- **`KEYWORDS`**:  
  Contiene las palabras clave que forman parte del lenguaje Gox.

---

### lexer.py

En este archivo se encuentra la clase principal `Gox`, encargada de iniciar y controlar el escaneo.

#### üîç M√©todo `_runFile`

Este m√©todo abre el archivo en **modo lectura binaria (`rb`)**, decodificando luego el contenido en una cadena de caracteres.  
Aunque inicialmente utilic√© este enfoque para seguir el libro, descubr√≠ que este modo asegura la lectura exacta de los bytes. Aun as√≠, algunos foros recomiendan utilizar `rb` solamente con archivos binarios, no con archivos de texto. ¬°Algo a considerar!

---

## Problemas que tuve durante el proceso

Durante el desarrollo de las **pruebas unitarias**, surgieron algunos problemas interesantes:

### Manejo de N√∫meros Negativos

El lexer no estaba reconociendo los n√∫meros negativos correctamente. El s√≠mbolo `-` era identificado como un token separado, no como parte del n√∫mero. Tuve que ajustar el c√≥digo para que los n√∫meros negativos fueran tratados como enteros completos.

### Manejo de Cadenas de Texto

Otro detalle surgi√≥ al probar el manejo de cadenas: el lexer las divid√≠a **car√°cter por car√°cter** en lugar de reconocerlas como un solo *lexeme*.  
Despu√©s de corregirlo, ahora las cadenas completas son reconocidas correctamente como una sola unidad.

---

## Estado Actual

El scanner ahora es capaz de:

- Identificar correctamente los tokens simples, literales y palabras clave.
- Leer archivos en modo binario para mayor precisi√≥n.
- Tratar correctamente n√∫meros negativos.
- Agrupar cadenas de texto como un solo token.

---

